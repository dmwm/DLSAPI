%  $Id: lfc-dls.tex,v 1.6 2005/12/19 22:22:03 afanfani Exp $

\documentclass[pdftex]{cmspaper}
\usepackage[bookmarksnumbered,bookmarksopen,bookmarksopenlevel=1,colorlinks,link
color=magenta,citecolor=blue,urlcolor=red,plainpages=false,pdfpagelabels]{hyperr
ef}

%
%

\begin{document}

%==============================================================================
% title page for few authors

\begin{titlepage}

% select one of the following and type in the proper number:
%   \cmsnote{2005/TBD}
%  \internalnote{2005/000}
%  \conferencereport{2005/000}
   \date{\today}

  \title{LFC evaluation as CMS Data Location Service}

%  \note{Draft Version \today...}
  \note{Draft Version 0.5}

  \begin{Authlist}
    ??? ???
       \Instfoot{wherever}{???? University, ???}
    Alessandra Fanfani
       \Instfoot{bologna}{Universit\`{a} di Bologna e Sezione dell' INFN, Bologna, ITALY}
    Stefano Belforte
       \Instfoot{trieste}{Sezione dell' INFN, Trieste, ITALY}
    Antonio Delgado, Flavia Donno, Andrea Sciaba' 
       \Instfoot{cern}{EIS, CERN}

  \end{Authlist}

%\collaboration{for the CMS collaboration}

  \begin{abstract}

    This note describes the evaluation of the LCG Local File catalog LFC as Data Location Service (DLS) component
    of the CMS Data Management (DM) project. 
\end{abstract} 

  
\end{titlepage}

\setcounter{page}{2}%JPP
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


\section{The DLS prototype based on LFC}
\label{sec:proto0}

 The Data Location Service (DLS) is part of the CMS Data Management system and allows to discover
 where replicas of the data may be located in the distributed computing system, as described in \cite{DLS}.  

 A first prototype implementing the basic DLS functionalities using LFC was developed.  

\subsection{CMS replica data structure in DLS}

The mapping of CMS index ({\em block-replica}) data structure into LFC fileds is: 
\begin{itemize}
\item block identifier, blockID  (string) $<-->$ LFCs' LFN
\item location, SE (string)  $<-->$ LFC's replica table (SURL or rather host field)
\item creation timestamp  (high precision time) $<-->$ there is no correspondance
\item last update timestamp (high precision time) $<-->$ LFC's replica last access
\item ``custodial'' attribute $<-->$ f\_type field of the LFC's replica (``P'' permanent, ``V'' volatile, etc..) 
\item other attributes  $<-->$ ?? ( user defined metadata, one field of 255chars, are associated to the LFN and not to the replica)
\end{itemize}


\subsection{DLS server}
 The DLS server is a global LFC instance. 
 \begin{itemize}
 \item The host is specified with the environment variable \$LFC\_HOST. 
 \item The path is specified with the environment variable \$LFC\_HOME .

 \end{itemize}

\subsection{DLS client}

\subsubsection{ CLI and API}
 There is a client command-line interface, that wrap python modules based on LFC python API, to perform the basic operations: 
 \begin{itemize}
   \item Add a Replica: 
\begin{flushleft}
  $\mbox{ dlslfc-add $<$fileblock1$>$  $<$SEnameA$>$ }$
\end{flushleft}
 
   Transactions are used if specified with option -t , otherwise sessions are used. Attributes can optionallu be specified (the specific syntax to use is under definition).

   \item Remove a Replica:
\begin{flushleft}
 $\mbox{ dlslfc-delete $<$fileblock1$>$ $<$SEnameA$>$ $<$SEnameB$>$ }$
\end{flushleft}

 Several options are provided to drive the deletion behaviour, for example
 to remove akk the replicas of a fileblock, to force the deletion of a custodial replica. However the deletion behaviour is under definition.

  \item Get location (SEs) hosting a file-block:
\begin{flushleft}
$\mbox{ dlslfc-get-se $<$fileblock1$>$ }$
\end{flushleft}

 Attributes can be optionally listed.

  \item Get file-block on a SE:
\begin{flushleft}
$\mbox{ dlslfc-get-datablock $<$SEname$>$}$
\end{flushleft}

  \item Update attributes:
\begin{flushleft}
$\mbox{ dlslfc-update  $<$fileblock1$>$ [attr1$=$val1 ...] $<$SEname$>$ [attr1$=$val1 ...]}$
\end{flushleft}
   \end{itemize}

The specification of API is under definition.

\subsubsection{ Installation requirements }

In addition to the DLS client tools, the LFC client is needed.
The LFC client is installed by default in an LCG UI. 
To install the LFC client the following RPMs are required :
\begin{itemize}
\item Globus security, i.e. the vdt\_globus\_essentials RPM
\item the lcg-dm-common RPM
\item the LFC-client RPM
\item the LFC-interfaces RPM, if you are using the Python or Perl interface
\end{itemize}
All these RMPs are relocatable.

[You need to create a valid proxy.]                 

                                                 
The libraries contained in the LFC and lcg-dm-common RPMs are:
                                                                                                        
/opt/lcg/lib/liblfc.so

/opt/lcg/lib/perl/lfc.so

/opt/lcg/lib/python/\_lfc.so

/opt/lcg/lib/libCsec\_plugin\_GSI.so

/opt/lcg/lib/libCsec\_plugin\_GSI\_thread.so

/opt/lcg/lib/libCsec\_plugin\_ID.so


\subsection{attributes}
 \begin{itemize}
  \item custodial

The ``custodial'' attribute of a replica can be specified using the
f\_type field of the LFC's replica (``P'' permanent, ``V'' volatile, etc..).

The f\_type attribute and the pin time (that could be used to somehow estimate access cost) were intended for DPM rather than LFC use, so one has to decide
whether or not to use them for custodial and access cost estimation 
although they were not intended for that.

The replica permanent/volatile attribute is set at creation time now,
and cannot be modified afterwards. There is currently no way to update that
attribute.
The work around is to delete the existing replica an create a new one with 
the attribute modified. 
A new method to modify this attribute could be also added, if it is a CMS requirement.

[ Not a requirement for the time being]

%{\bf FIXME:} Is it possible to retrieve the value of this attribute?
% dlslfc-get-se -l
%% 4.bis could other types be defined, up to this beeing an N-Byte
%% code that we use as we like ? Or is there a standard e.g. in SRM ?
%%????

  \item timestamps

The replica last update timestamp is described by the LFC's replica last access.

The replica creation timestamp doesn't exist. It could be added to the catalog if it is a CMS requirement.

[Not a requirement for the time being]
% Not a requirement for the time being

  \item additional attributes

The addition of new replica attributes is not foreseen, since LFC is not a metadata catalog. 
Other solutions can be found for that.                                                     

 \end{itemize}


\section{Testing of perfomances}


\subsection {Get data locations}

The typical use cases will be to get locations of one fileblock or N fileblocks (with N up to 1000??).
[The query based on a single fileblock will be particularly important for data location performed by the Resource Broker via DLI, where fileblocks will be queries one by one (as far as it is now).]

For a single query, most of the time is probably lost in the connection 
establishment and the authentication. 
The time spent to list the locations of a single fileblock ("time dlslfc-get-se 1fileblock") 
as a function of the N locations the fileblock is hosted at is reported in Tab.~\ref{get-se-1fileblock}.

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   N  & time \\ \hline
   1  & 0.77 s \\ \hline
   5  & 0.82 s  \\ \hline
   10 & 0.90 s \\ \hline
   20 & 1.02 s \\ \hline
  100 & 2.10 s \\ \hline
\end{tabular}
\caption {Time for listing locations of a signle fileblock, when there are N locations of that fileblock. }\label{get-se-1fileblock}
\end{center}
\end{table}

Performance improvements are foreseen by the LFC developers, introducing
the new API method (lfc\_getreplicas), for the single fileblock (1-lfn) query
with  almost constant response time for any number of replicas and even more improvements 
for the bulk N-fileblock query.


The times reported in Tab.~\ref{get-se-1fileblock} were obtained from the command line tools. 
Although they involve little else than querying the LFC, the times are slightly better 
running the interesting part from within the python interpreter (avoid of loading python within 
the time measurement), as reported in Tab.~\ref{get-se-1fileblock-test}.

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   N  & time \\ \hline
   1  & 0.58 s \\ \hline
   5  & 0.61 s  \\ \hline
   10 & 0.70 s \\ \hline
   20 & 0.83 s \\ \hline
  100 & 1.90 s \\ \hline
\end{tabular}
\caption {Time for listing locations of a signle fileblock, when N locations of that fileblock are available. Times excluding python loading}\label{get-se-1fileblock-test}
\end{center}
\end{table}

%   Deletion of an entry (and its 3 replicas): 1.3 s
%  
%   Retrieve SEs where datablock is located (3 SEs): 0.6 s
%


\subsection {Timing tests for impact of sessions/transactions in the operations}

In this section preliminary timing tests including all the LFC calls within a session (i.e. single authentication with the LFC) or a transaction, are reported.

Although these tests are not completely rigorous, they show that using sessions reduces times in 
a factor of 10 in addition (Tab.~\ref{dlslfc-add}), a factor of 3 in deletion (Tab.~\ref{dlslfc-del}) and has almost of no effect in listing replicas (Tab.~\ref{dlslfc-get-se}, Tab.~\ref{dlslfc-get-db}).
LFC listing operations are not performed within a session so the obtained results are expected. There is LFC development going on in this area and it will be corrected in future LFC versions (timescale:1/2 weeks away?).


\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|c|}         \hline
   {\bf dlslfc-add}  & N=100 entries & N=1000 entries \\ \hline
 No session          & 108 s       & 1165 s \\ \hline
 session             & 9.56 s      & 90 s \\ \hline
 transaction         & 8.5 s      & 80 s \\ \hline        
\end{tabular}
\caption {Timing for adding N replicas.(N is the number of items in the query)}\label{dlslfc-add}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|c|}         \hline
   {\bf dlslfc-delete}  & N=100 entries & N=1000 entries \\ \hline
 No session          & 111 s     & 1159 s \\ \hline
 session             & 34 s      & 344 s \\ \hline
 transaction         & 35 s      & 337 s \\ \hline        
\end{tabular}
\caption {Timing for deleting N replicas. }\label{dlslfc-del}
\end{center}
\end{table}


\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|c|}         \hline
   {\bf dlslfc-get-se}  & N=100 entries & N=1000 entries \\ \hline
 No session          & 30.18 s     & 288 s \\ \hline
 session             & 30 s      & 257 s \\ \hline
\end{tabular}
\caption {Timing for getting data location for N fileblocks .}\label{dlslfc-get-se}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|c|}         \hline
   {\bf dlslfc-get-datablock}  & N=113 replicas & N=2705 replicas \\ \hline
 No session          & 43.8 s     & 717 s \\ \hline
 session             & 41 s      & 691 s \\ \hline
\end{tabular}
\caption {Timing for listing fileblocks present at a given location. The time is reported for location having N fileblocks stored there. }\label{dlslfc-get-db}
\end{center}
\end{table}

Note that the population in the database during the testing is at least several thousands, 
altough the exact population is not know (no permissions to query all the directories).
How the overall population of the database affect the performances?


\subsection{secure versus in-secure LFC}

Running an in-secure version of LFC on a different port for read-only accesses
and sharing the same Database of the secure one seems to be technically possible.
However the LFC do not reccomend nor support having in-secure LFC catalog,
even if it is read-only. It would be experiment responsability to do that, and it 
should work against a dedicated back-end database (so no other experiments are exposed).

{\bf FIXME: } are the experiment supposed to share the same back-end database?


\subsection{ Concurrent queries }
 
In this section preliminar tests on performances when several clients 
are concurrentlly accessing the LFC are reported
\ref{dlslfc-add-parallel}, \ref{dlslfc-get-se-parallel}.
[These tests were perfomed from a UI over the WAN].

Currently the LFC server has only 20 threads, thus only
20 clients can be served at the same time. 
Increasing the number of concurrent clients above the
number of threads being served cause degrade
in performances and sometimes error in connecting to
the server (for example some connections are timed out
when more then 50 dlslfc-get-se clients are used).


An increase in the number of threads served by the LFC server
is planned. As long as the machine itself can handle the load and 
the DB does not become a bottleneck, the number of threads is 
almost arbitrary. An indication of how many parallel queries 
are expeceted for the DLS would help defining that.


{\bf FIXME:} check and comments more the results?  

\subsubsection{ Inserting replicas}

Few errors (<10 times "Error creating the LFN: File exists" ) 
occurred when inserting with 10 concurrent clients and 100 
operations per client or 20 concurrent clients and 
50 operations per client.
{\bf FIXME} it might be a bug in the inserting script but
that's weird.

%\begin{table}[!htbp]
%\begin{center}
% \begin{tabular}{|l|c|c|c|c|c|c|}         \hline
% {\bf dlslfc-add} : & N = 1  & N  = 5  & N = 10 & N = 20 & N = 50 & N = 100 \\ \hline
%  average & 1.3s & 1.6s & 3.9s &  5.8s &  11.8s  & 22.3s \\ \hline
%  max     & - & 1.7s & 5.5s &  9.2s & 20.9s &  50.9s \\ \hline
%  min     &  - &  1.6s & 2.2s  & 2.3s & 2.9s  & 2.8s \\ \hline
%\end{tabular}
%\caption {Timing for adding 1 replicas with N concurrent clients.}\label{dlslfc-add}
%\end{center}
%\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|c|c|c|c|c|}         \hline
 {\bf dlslfc-add} : & N = 1  & N  = 5  & N = 10 & N = 20 & N = 50 & N = 100 \\ \hline
  average           & 1.3s   & 1.2s    & 2.64s  &  3.4   & 7.1s   & 11.8s \\ \hline
  max               & -      & 1.5s    & 2.96s  &  4.9s  & 12.4s  & 26.4s \\ \hline
  min               &  -     & 0.95s   & 1.4s   &  2.0s  & 2.0s   & 2.0s \\ \hline
\end{tabular}
\caption {Timing for adding 1 replicas with N concurrent clients. The replica is added using transactions.}\label{dlslfc-add-parallel}
\end{center}
\end{table}


\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   {\bf dlslfc-add} : & N concurrent clients = 10 \\ 
    & M operations per client = 50\\ \hline
    average & 1.280s \\ \hline
    max & 4.288s \\ \hline
    min &  0.630s \\ \hline
    rate  & 7.6 \\ \hline
\end{tabular}
\caption {Timing for adding 500 replicas with 10 concurrent clients. Each replica is added using transactions.}\label{dlslfc-add}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   {\bf dlslfc-add} : & N concurrent clients = 10  \\
   & M operations per client = 100\\ \hline
    average &  1.323s \\ \hline
    max & 3.160s \\ \hline
    min &  0.664s \\ \hline
    rate  & 7.5 \\ \hline
\end{tabular}
\caption {Timing for adding 1000 replicas with 10 concurrent clients. Each replica is added using transactions.}\label{dlslfc-add}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   {\bf dlslfc-add} : & N concurrent clients = 20  \\ 
 & M operations per client = 50\\ \hline
    average &  2.131s \\ \hline
    max & 7.418s \\ \hline
    min & 0.608s \\ \hline
    rate  & 9.07 \\ \hline 
\end{tabular}
\caption {Timing for adding 1000 replicas with 20 concurrent clients.Each replica is added using transactions.}\label{dlslfc-add}
\end{center}
\end{table}

\subsubsection{Get replica location}

The operation to get the location of a given fileblock (dlslfc-get-se)
currently use two different threads (one to open a session and the other
for the listing operation), thus showing a more significant degrade
in performances when the number of concurrent clients increases.
For example 20 concurrent dlslfc-get-se (\ref{dlslfc-get-se-parallel})
clients open a session and get the 20 server threads busy.
Then none of them can get a new thread for the listing operation.
After 60 seconds, the no activity timeout occurs, and the session
is ended (but operations go on anyway, only outside of the session).
The listing can at that point (not before 60 seconds) take place
and we get all those long times.

The new LFC methods being developped should eliminate the use of the 
second thread in dlslfc-get-se , so the number of threads can be 
used integrally.


When more then 50 dlslfc-get-se clients are used 
some connections to the LFC server are timed out.


%\begin{table}[!htbp]
%\begin{center}
% \begin{tabular}{|l|c|c|c|c|c|c|}         \hline
% {\bf dlslfc-get-se} : & N = 1  & N  = 5  & N = 10 & N = 20 & N = 50 & N = 100 \\ \hline
%  average & 1.7s & 1.9s & 3.1s &  78.6s &  100.8s  & 168.6s \\ \hline
%  max     & -    & 2.0s & 5.5s &  96.4s & 191.5s &  213.4s \\ \hline
%  min     &  -   & 1.9s & 2.4s  & 62.7s & 63.0s  & 63.7s \\ \hline
%\end{tabular}
%\caption {Timing for getting location for 1 replica with N concurrent clients.}\label{dlslfc-add}
%\end{center}
%\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|c|c|c|c|c|}         \hline
 {\bf dlslfc-get-se} : & N = 1  & N  = 5  & N = 10 & N = 20 & N = 50 & N = 100 \\ \hline
  average           & 0.5s   & 1.2s   & 2.1s  &  79.8s  & 98.690s  & 169.9s \\ \hline
  max               &  -     & 1.2s   & 2.1s  &  119.7s  & 191.4s  & 237.7s \\ \hline
  min               &  -     & 1.2s   & 2.0s  &  61.8s  & 62.8s   & 62.9s \\ \hline
\end{tabular}
\caption {Timing for getting location for 1 replica  with N concurrent clients.}\label{dlslfc-get-se-parallel}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   {\bf dlslfc-get-se} : & N concurrent clients = 10 \\ 
    & M operations per client = 50\\ \hline
    average & 1.931s \\ \hline
    max & 4.884s \\ \hline
    min & 0.645s \\ \hline
    rate  & 5.1 \\ \hline
\end{tabular}
\caption {Timing for getting location for 500 replicas with 10 concurrent clients.}\label{dlslfc-get-se}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   {\bf dlslfc-get-se} : & N concurrent clients = 10  \\
   & M operations per client = 100\\ \hline
    average & 1.866s \\ \hline
    max & 4.511s \\ \hline
    min & 0.676s  \\ \hline
    rate  & 5.3 \\ \hline
\end{tabular}
\caption {Timing for getting location for 1000 replicas with 10 concurrent clients.}\label{dlslfc-get-se}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}
 \begin{tabular}{|l|c|}         \hline
   {\bf dlslfc-get-se} : & N concurrent clients = 20  \\ 
 & M operations per client = 50\\ \hline
    average & 4.501s \\ \hline
    max & 120.298s \\ \hline
    min &  0.482s  \\ \hline
    rate  & 4.0 \\ \hline
\end{tabular}
\caption {Timing for get location for 1000 replicas with 20 concurrent clients.}\label{dlslfc-get-se}
\end{center}
\end{table}
\subsection {Other tests}

\begin{itemize}

 \item investigate what makes adding a new replica slower wrt to the bare MySQL CMS prototype. 
      
       It took about 1h 20min to insert into LFC about 2900 entries, one at the time (with old command-line).
       It took about 7min with the DLS python/MySQL prototype.
       The difference seems to be due to the authentication, because when using sessions the 
       inserting time reduces by a factor of 10. 

 \item investigate the slowness of dlslfc-get-datablock 
       Retrieving list of fileblocks in one SE will be used not often and is outside the main workflow, so perormance of that is not very important at the moment.
       
                                                                                                  
  \end{itemize} 


\subsection{ Naive model for expected DLS performance}

\begin{itemize}

\item number of {\em block-replica} in a year

  The total disk and space storage divided by the average fileblock size.

  The overall storage at Tier-0 and all Tier-1/2s foreseen in 2008 (\cite{CTDR})  is about 33PB. Assuming an average file-block size of 1TB, the
  total number of {\em block-replica} is of order $10^{4}$-$10^{5}$.

\item number of file-blocks in a year

  The total size of events divided by the average fileblock size.

  Assuming the most relevant data in term of size are RAW (1.5MB/evt),
  RECO (0.25MB/evt) and MC (~4MB/evt?) data and $1.5 \times 10^{9}$ events,
  with 2 reprocessing phases, the total size is about 10 PB.
  Assuming an average file-block size of 1TB, the
  total number of file-blocks in a year is of the order $10^{4}$.

%%% RAW event has 1.5MB , RECO event has 0.25MB
%%% Sim event has 2MB , (SimDigi?? has 1.5MB), RecSim has 0.4MB
%% $1.5 \times 10^{9}$ events $\times 2.25MB$ (RAW+3RECO) = about 3PB
%% $1.5 \times 10^{9}$ events $\times 3.9MB$ (MC) = about 6PB
%
\item number of queries for analysis

 Assuming:
 \begin{itemize}
  \item the whole data sample ($\sim 10K$ file-blocks) is analysed
        with 5 different analyses every 20 days (as mentioned for AOD in \cite{CM})
  \item each file-block ($\sim 1TB$) is analysed by 1000 jobs, i.e. each job
        analyse 1GB of data
  \item each job does a query to DLS to find the location of the file-block it needs
 \end{itemize}

 \mbox{5 analysis $\times 10K$ fileblocks $\times 1000$ queries} = \mbox{ $5 \times 10^{7}$ }

 \mbox{ 20 days } = \mbox{ $1.7 \times 10^{6}$ sec}

 the rate is about 30Hz ( order of 10-100Hz )

\end{itemize}

\section{Open Issues}
\begin{itemize}
 \item specification of DLS API and CLI syntax (see \ref{appendix})
 \item attributes : use of attributes that were originally thought for different purposes?
 \item performances when getting location of data (dlslfc-get-se). 

The new LFC methods were not available as python API, because the SWIG wrapping of the C API was not trivial (as it was for old methods) and the development of them was a lower priority. The python wrapping of the new lfc\_getreplica was implemented and one should mimic that for other methods.


In order to use the new methods:
\begin{itemize}

\item Use an LFC server that support them (version 1.4.1)
    You can use lfc-cms.cern.ch, but not (yet) lfc-cms-test.cern.ch
\item Use a UI where the new C client has been installed (version 1.4.1)
    That is not yet in lxplus, but you can get it from:
    /afs/cern.ch/project/gd/RpmDir\_i386-sl3/lcg/LFC-client-1.4.1-1sec\_sl3.i386.rpm
\item Install the python interface for this C client (not yet in 1.4.1, but
in a test RPM developed ad hoc by me and Sophie Lemaitre).

\item use the C DLI client (lfc-dli-client) or the new python API for getting data location (dlslfc\_get\_se\_new.py)
\end{itemize}


 
 \item reliability, error conditions: 
       \begin{itemize}
       \item when much more clients (50-100) than available LFC server threads (20) are used some connections 
       to the LFC server are timed out
       \item inserting replicas, even with less concurrent clients than LFC threads, fails with "Internal Error" in $<1\%$ : need to investigate
      \end{itemize}
 \item investigate DLI usage

 There is a DLI client (written in C), which just queries the LFC via
 the DLI giving an LFN and returning the associated SFNs. This client has
 the real code the RB uses, so it could be used to measure how long it
 takes for the LFC to reply to single queries.


\end{itemize}  


\subsection{CLI and API specification preliminar proposal}
\label{appendix}

\subsubsection{CLI}

It might be desirable to avoid using positional arguments; i.e. to distinguish
what is a fileblock or a SE, and to which SE (or fileblock) belong the different
attributes specified, based on the order in which they were specified in the
command line.
                                                                                                                      NOTE: This practice is not completely infrequent, and the user has always the
possibility to use the API instead, so the current syntax should probably be
replaced only if the alternative is more convenient (easier) to use.

\begin{itemize}
\item Use options rater than arguments for the specification of fblocks, replicas, attrs. 

Options for dlslfc-add (and dlslfc-update):

\begin{flushleft}
  $\mbox{ dlslfc-add --fb $<$fileblock1$>$ [--fb-at a1$=$v1..]  --se $<$SEnameA$>$ [--rep-at a1$=$v1..]}$
\end{flushleft}

\begin{flushleft}
  $\mbox{ dlslfc-add --fb $<$fileblock1$>$ [a1$=$v1..]  --se $<$SE1$>$ [a1$=$v1..] }$
\end{flushleft}

\begin{flushleft}
  $\mbox{ dlslfc-add  [--fb-at a1$=$v1..] --se $<$SE1$>$ [--rep-at a1$=$v1..] $<$fileblock1$>$ }$
\end{flushleft}


Options for dlslfc-delete:


"-a" case seems all right:
\begin{flushleft}
   $\mbox{ dlslfc-delete [-v] [-k | -l] [-x] [-a] <fileblock> }$
\end{flushleft}

for the other:
\begin{flushleft}
   $\mbox{ dlslfc-delete [-v] [-k ] [-x] $<$fileblock$>$ $<$SE1$>$ [$<$SE2$>$ ..]}$
\end{flushleft}                                                                                                                                               
An option for SEs could be added:
\begin{flushleft}
   $\mbox{ dlslfc-delete [-v] [-k ] [-x] --se $<$SE1$>$ [--se $<$SE2$>$ ..]  $<$fileblock$>$}$
\end{flushleft} 

\item Allow an interactive specification of the different parameters. I.e., the tool would
ask for fileblock, its attributes, then each one of the replicas and the attributes of each.

\item Any other idea?

\end{itemize}

\subsubsection{API}
Current methods have complicated arguments due to the need to specify complex
relations like: several replicas for 1 lfn, having each replica several key=val
pairs for its attributes, and also having the lfn a different list of attribute
pairs.
                                                                                                                                               
One possibility for the API would be to define objects to group things (rather
like C structures). E.g.:
\begin{itemize}                                                                                                                   
\item "DlsEntry" class:
  \begin{itemize} 
  \item DlsFileblock
  \item DlsReplica list
   \end{itemize}                                                                                                                                             
\item "DlsFileblock" class:
   \begin{itemize}
   \item LFN
   \item GUID *
   \item DlsAttribute list
   \end{itemize}                                                                                                                                            
\item "DlsReplica" class:
   \begin{itemize}
   \item Host
   \item SFN **
   \item DlsAttribute list
   \end{itemize}                                                                                                                                             
\item "DlsAttribute" class:
   \begin{itemize}
   \item Key
   \item Value
   \end{itemize}
\end{itemize}                                                                                                                                                                                                                                                                
* GUID could be just another attribute in the list, or be explicit (to ensure it's not not null/default)

** SFN could be just another attribute in the list, or be explicit (to ensure it's not not null/default)
                                                                                                                                               
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{9}
  \bibitem{DLS} {\bf ????}, , {\bf The CMS Data Location Service} 
  \bibitem{LFC} {\bf LFC Administrative Guide} https://edms.cern.ch/file/579088/1/LFC-Administrator-Guide-1.3.5.pdf \\ {\bf LCG-2 User guide } https://edms.cern.ch/file/454439//LCG-2-UserGuide.html 
  \bibitem{CTDR} {\bf CERN/LHCC 2005-023}, , {\bf CMS Computing Technical Design Report}
  \bibitem{CM} {\bf CMS Note 2004/031}, C. Grandi, D. Stickland,
               L. Taylor, {\bf The CMS Computing Model}

\end{thebibliography}
 
%------------------------------------------------------------------------------
\pagebreak

\end{document}
